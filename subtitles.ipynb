{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAG6186DfJLA"
      },
      "source": [
        "This is a notebook for transcribing and translating subtitles using Google Colab, OpenAI API and Whisper.\n",
        "\n",
        "Please read the README for further information on parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7YdVaUvZ5yx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Need to modify\n",
        "episode_path = \"20250424\"\n",
        "# You can add extra context here:\n",
        "guest_context = \"The guest in this episode was [...]. She is a [...]. \" # Leave empty \"\" if no guests\n",
        "extra_context = \"This time, the topic was [...]. \" # Describe the topic and important keywords\n",
        "\n",
        "# Might need to modify. One batch ~10-30 tokens. Larger batch = more context, but higher risk of hitting API limits\n",
        "batch_size = 100\n",
        "\n",
        "# Need to modify once (first time)\n",
        "background_context = \"The subtitles are from a podcast between [...]. Generally, they talk about [...]. \"\n",
        "language = \"et\" # ISO 639-1. Language 2-letter code\n",
        "language_full = \"Estonian\" # Full name of language\n",
        "drive_path = \"/content/drive/MyDrive/my_podcast_path\" # if the files are under your own drive, then the path you see in Drive UI comes after \"/content/drive/MyDrive/\"\n",
        "audiofile_name = \"audio.mp3\"\n",
        "\n",
        "# Probably don't need to modify, unless you prefer something else:\n",
        "initial_subtitles_name = f\"init_{language}.srt\"\n",
        "corrected_subtitles_name = f\"final_{language}.srt\"\n",
        "translated_subtitles_name = f\"final_en.srt\"\n",
        "\n",
        "whisper_model = \"large-v3\"\n",
        "openai_model = \"gpt-4.1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXnNk_OcwiEw",
        "outputId": "cb096f52-5483-4e4b-e0dd-40c823670c6a"
      },
      "outputs": [],
      "source": [
        "!pip install -U openai-whisper\n",
        "!pip install -U openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrH6hiHRwmAu",
        "outputId": "67a16c52-e38e-415c-d2bf-f238ac72f454"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "\n",
        "model_size = whisper_model\n",
        "\n",
        "model = whisper.load_model(model_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NhFDd3gOkLJk"
      },
      "outputs": [],
      "source": [
        "result = model.transcribe(os.path.join(drive_path,episode_path,audiofile_name), language=language)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i4dd79xEkPxb"
      },
      "outputs": [],
      "source": [
        "def format_timestamp(seconds):\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    milliseconds = int(round((seconds - int(seconds)) * 1000))\n",
        "    return f\"{hours:02}:{minutes:02}:{secs:02},{milliseconds:03}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qTFdaLA7W2SS"
      },
      "outputs": [],
      "source": [
        "srt_text = \"\"\n",
        "sgm_len = len(result[\"segments\"])\n",
        "for s in result[\"segments\"]:\n",
        "  s_id = s[\"id\"]\n",
        "  s_start = s[\"start\"]\n",
        "  s_end = s[\"end\"]\n",
        "  s_text = s[\"text\"].strip()\n",
        "\n",
        "  if s_id < sgm_len-1 and s_id > 0:\n",
        "    srt_text += \"\\n\\n\"\n",
        "\n",
        "  srt_text += f\"{s_id}\\n{format_timestamp(s_start)} --> {format_timestamp(s_end)}\\n{s_text}\"\n",
        "\n",
        "\n",
        "with open(os.path.join(drive_path,episode_path,initial_subtitles_name), \"w\", encoding=\"utf-8\") as file:\n",
        "  file.write(srt_text)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwgmliQEP9k-"
      },
      "outputs": [],
      "source": [
        "\n",
        "import openai\n",
        "import getpass\n",
        "from google.colab import files\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('oai')\n",
        "\n",
        "client = openai.OpenAI()\n",
        "\n",
        "\n",
        "# Read and batch the subtitle blocks\n",
        "def load_srt_blocks(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "    return content.strip().split('\\n\\n')\n",
        "\n",
        "blocks = load_srt_blocks(os.path.join(drive_path,episode_path,initial_subtitles_name))\n",
        "\n",
        "def batch_blocks(blocks, batch_size=batch_size):\n",
        "    for i in range(0, len(blocks), batch_size):\n",
        "        yield blocks[i:i + batch_size]\n",
        "\n",
        "# Prompt templates\n",
        "\n",
        "orig_prompt_template = (\n",
        "    f\"You will receive subtitle segments in SRT format in {language_full}. \"\n",
        "    f\"{background_context} \"\n",
        "    f\"{guest_context} \"\n",
        "    f\"{extra_context} \"\n",
        "    f\"Please correct typos and fix grammar where needed, but preserve meaning. \"\n",
        "    f\"Do not translate. Keep the original SRT format with timestamps unchanged.\\n\\n{{batch}}\\n\\nCorrected subtitles:\"\n",
        ")\n",
        "\n",
        "en_prompt_template = (\n",
        "    f\"Translate the following corrected {language_full} SRT subtitles to English. \"\n",
        "    f\"Keep the timestamps and formatting the same. Do not add or remove lines.\\n\\n{{batch}}\\n\\nTranslated subtitles:\"\n",
        ")\n",
        "\n",
        "# OpenAI API call\n",
        "def gpt_call(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=openai_model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a subtitle correction and translation assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Process batches\n",
        "corrected_orig = []\n",
        "translated_en = []\n",
        "\n",
        "for batch_num, batch in enumerate(batch_blocks(blocks), start=1):\n",
        "    print(f\"Processing batch {batch_num}...\")\n",
        "\n",
        "    joined_batch = '\\n\\n'.join(batch)\n",
        "\n",
        "    # Correct Estonian\n",
        "    orig_prompt = orig_prompt_template.format(batch=joined_batch)\n",
        "    corrected = gpt_call(orig_prompt)\n",
        "    corrected_orig.append(corrected)\n",
        "\n",
        "    # Translate to English\n",
        "    en_prompt = en_prompt_template.format(batch=corrected)\n",
        "    translated = gpt_call(en_prompt)\n",
        "    translated_en.append(translated)\n",
        "\n",
        "# Write outputs \n",
        "with open(os.path.join(drive_path,episode_path,corrected_subtitles_name), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\\n\".join(corrected_orig))\n",
        "\n",
        "with open(os.path.join(drive_path,episode_path,translated_subtitles_name), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\\n\".join(translated_en))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
